{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fccc852fab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_lightning import crop, show_tensor_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_dropout=False, use_bn=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        if use_bn:\n",
    "            self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.use_bn = use_bn\n",
    "        \n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout()\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_channels, use_dropout=False, use_bn=True):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        if use_bn:\n",
    "            self.batchnorm = nn.BatchNorm2d(in_channels * 2)\n",
    "        self.use_bn = use_bn\n",
    "        \n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout()\n",
    "        self.use_dropout = use_dropout\n",
    "            \n",
    "        self.conv_block1 = ConvBlock(in_channels, in_channels*2, use_dropout, use_bn)\n",
    "        self.conv_block2 = ConvBlock(in_channels*2, in_channels*2, use_dropout, use_bn)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, use_dropout=False, use_bn=True):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, input_channels // 2, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(input_channels, input_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(input_channels // 2, input_channels // 2, kernel_size=2, padding=1)\n",
    "        if use_bn:\n",
    "            self.batchnorm = nn.BatchNorm2d(input_channels // 2)\n",
    "        self.use_bn = use_bn\n",
    "        self.activation = nn.ReLU()\n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout()\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "    def forward(self, x, skip_con_x):\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv1(x)\n",
    "        skip_con_x = crop(skip_con_x, x.shape)\n",
    "        x = torch.cat([x, skip_con_x], axis=1)\n",
    "        x = self.conv2(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(pl.LightningModule):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels = 32, depth=6):\n",
    "        super(Generator, self).__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=1)\n",
    "        \n",
    "        self.conv_final = nn.Conv2d(hidden_channels,\n",
    "                                    out_channels,\n",
    "                                    kernel_size=1)\n",
    "        self.depth = depth\n",
    "\n",
    "        self.contracting_layers = []\n",
    "        self.expanding_layers = []\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # encoding/contracting path of the Generator\n",
    "        for i in range(depth):\n",
    "            self.contracting_layers += [\n",
    "                DownConv(hidden_channels * 2**i, use_dropout=True if i<3 else False)\n",
    "            ]\n",
    "        \n",
    "        # Upsampling/Expanding path of the Generator\n",
    "        for i in range(1, depth + 1):\n",
    "            self.expanding_layers += [UpConv(hidden_channels * 2**i)]\n",
    "\n",
    "        self.contracting_layers = nn.ModuleList(self.contracting_layers)\n",
    "        self.expanding_layers = nn.ModuleList(self.expanding_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        depth = self.depth\n",
    "        contractive_x = []\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        contractive_x.append(x)\n",
    "\n",
    "        for i in range(depth):\n",
    "            x = self.contracting_layers[i](x)\n",
    "            print(x.shape)\n",
    "            contractive_x.append(x)\n",
    "        \n",
    "        for i in range(depth - 1, -1, -1):\n",
    "            x = self.expanding_layers[i](x, contractive_x[i])\n",
    "            print(x.shape)\n",
    "        x = self.conv_final(x)\n",
    "        \n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_channels, hidden_channels=8):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_channels, kernel_size=1)\n",
    "        self.contract1 = DownConv(hidden_channels, use_bn=False)\n",
    "        self.contract2 = DownConv(hidden_channels * 2)\n",
    "        self.contract3 = DownConv(hidden_channels * 4)\n",
    "        self.contract4 = DownConv(hidden_channels * 8)\n",
    "        self.final = nn.Conv2d(hidden_channels * 16, 1, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], axis=1)\n",
    "        x0 = self.conv1(x)\n",
    "        x1 = self.contract1(x0)\n",
    "        x2 = self.contract2(x1)\n",
    "        x3 = self.contract3(x2)\n",
    "        x4 = self.contract4(x3)\n",
    "        xn = self.final(x4)\n",
    "        return xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 hidden_channels=32,\n",
    "                 depth=6,\n",
    "                 learning_rate=0.0002,\n",
    "                 lambda_recon=None):\n",
    "        \n",
    "        self.gen = Generator(in_channels, out_channels, hidden_channels, depth)\n",
    "        self.disc = Discriminator(input_channels, hidden_channels=8)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # intializing weights\n",
    "        self.gen = self.gen.apply(weights_init)\n",
    "        self.disc = self.disc.apply(weights_init)\n",
    "\n",
    "        self.adv_criterion = nn.BCEWithLogitsLoss()\n",
    "        self.recon_criterion = nn.L1Loss()\n",
    "        if lambda_recon is None:\n",
    "            lambda_recon = 200\n",
    "        self.lambda_recon = lambda_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 256, 256])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 512, 16, 16])\n",
      "torch.Size([1, 1024, 8, 8])\n",
      "torch.Size([1, 2048, 4, 4])\n",
      "torch.Size([1, 1024, 8, 8])\n",
      "torch.Size([1, 512, 16, 16])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 32, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "unet(torch.randn(1, 3, 256, 256))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(3, 3, depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 512, 16, 16])\n",
      "torch.Size([1, 1024, 8, 8])\n",
      "torch.Size([1, 2048, 4, 4])\n",
      "torch.Size([1, 1024, 8, 8])\n",
      "torch.Size([1, 512, 16, 16])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 32, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(torch.randn(1, 3, 256, 256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
